{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# For auto reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available. PyTorch version: 1.3.1  Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "gpu_index = 0\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:{}\".format(gpu_index))\n",
    "    print('CUDA available. PyTorch version:', torch.__version__, ' Device:', device)\n",
    "else:\n",
    "    print('CUDA is not available. Stopped.')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the models...\n",
      "ResNet18 added.\n",
      "BResNet18 added.\n",
      "BResNet101 added.\n",
      "All models built and added to the list.\n",
      "Model list:\n",
      "    ResNet-18\n",
      "    B-ResNet-18\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'models.resnet.BasicBlock'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'models.resnet.ResNet'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "Model: ResNet-18, Params: 11.1740, FLOPs(M): 556.65\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Customize rule count_bibdConv2d() <class 'bibd_layer.BibdConv2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'models.resnet_bibd.BBasicBlock'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'models.resnet_bibd.BResNet'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "Model: B-ResNet-18, Params: 22.1594, FLOPs(M): 54.71\n"
     ]
    }
   ],
   "source": [
    "from models.resnet import ResNet18, ResNet34, ResNet50, ResNet101\n",
    "from models.resnet_bibd import BResNet18, BResNet34, BResNet50, BResNet101\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "n = 3\n",
    "\n",
    "print('Building the models...')\n",
    "model_list = []\n",
    "model_list.append(ResNet18().to(device))\n",
    "print('ResNet18 added.')\n",
    "model_list.append(ResNet34().to(device))\n",
    "print('ResNet34 added.')\n",
    "model_list.append(ResNet50().to(device))\n",
    "print('ResNet50 added.')\n",
    "# model_list.append(ResNet101().to(device))\n",
    "# print('ResNet101 added.')\n",
    "model_list.append(BResNet18().to(device))\n",
    "print('BResNet18 added.')\n",
    "model_list.append(BResNet34().to(device))\n",
    "print('BResNet34 added.')\n",
    "model_list.append(BResNet50().to(device))\n",
    "print('BResNet50 added.')\n",
    "# model_list.append(BResNet101().to(device))\n",
    "# print('BResNet101 added.')\n",
    "print('All models built and added to the list.')\n",
    "print('Model list:')\n",
    "for model in model_list:\n",
    "    print('    {}'.format(model.name))\n",
    "\n",
    "\n",
    "from thop import profile\n",
    "import sys\n",
    "sys.path.append('../bibd')\n",
    "from bibd_layer import BibdLinear, RandomSparseLinear, generate_fake_bibd_mask, BibdConv2d, RandomSparseConv2d, bibd_sparsity\n",
    "\n",
    "\n",
    "def count_model(model_to_count, x, y):\n",
    "#     print(x.size())\n",
    "#     print(x)\n",
    "    in_features = len(x)\n",
    "    out_features = len(y)\n",
    "    \n",
    "    print('in_features = {}, out_features = {}'.format(in_features, out_features))\n",
    "    \n",
    "    # per output element\n",
    "    total_mul = in_features\n",
    "    total_add = in_features - 1\n",
    "    num_elements = y.numel()\n",
    "    total_ops = (total_mul + total_add) * num_elements\n",
    "    # one zero weight, minus 2 ops\n",
    "    total_ops -= (in_features * out_features - np.sum(generate_fake_bibd_mask(in_features, out_features))) * 2\n",
    "\n",
    "    model_to_count.total_ops += torch.Tensor([int(total_ops)])\n",
    "\n",
    "\n",
    "def count_bibdConv2d(m, x: (torch.Tensor,), y: torch.Tensor):\n",
    "    '''\n",
    "    Reference: https://github.com/Lyken17/pytorch-OpCounter/blob/dbc052ec2d914e950b3e0fa24d3eea753a4e0bb7/thop/vision/basic_hooks.py#L15\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    x = x[0]\n",
    "\n",
    "    kernel_ops = torch.zeros(m.fpWeight.size()[2:]).numel()  # Kw x Kh\n",
    "#     bias_ops = 1 if m.bias is not None else 0\n",
    "    bias_ops = 0 # For our current implementation of BibdConv2d, bias is always disabled implicitly\n",
    "\n",
    "    # N x Cout x H x W x  (Cin x Kw x Kh + bias)\n",
    "    total_ops = y.nelement() * (m.in_channels // m.conGroups * kernel_ops + bias_ops)\n",
    "    \n",
    "    # Multiply total_ops with the sparsity\n",
    "    total_ops *= bibd_sparsity(m.in_channels, m.out_channels)\n",
    "\n",
    "    m.total_ops += torch.DoubleTensor([int(total_ops)])\n",
    "\n",
    "\n",
    "custom_ops = {\n",
    "    BibdConv2d: count_bibdConv2d,\n",
    "    RandomSparseConv2d: count_bibdConv2d\n",
    "}\n",
    "\n",
    "\n",
    "for model in model_list:\n",
    "    input = torch.randn(1, 3, 32, 32).to(device)\n",
    "    flops, params = profile(model, inputs=(input, ), custom_ops=custom_ops)\n",
    "    print('Model: %s, Params: %.4f, FLOPs(M): %.2f' % (model.name, params / (1000 ** 2), flops / (1000 ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
