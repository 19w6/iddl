{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# For auto reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset with MLP\n",
    "\n",
    "[reference](https://github.com/CSCfi/machine-learning-scripts/blob/master/notebooks/pytorch-mnist-mlp.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.3.1  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Next we'll load the MNIST data. First time we may have to download the data, which can take a while.\n",
    "\n",
    "Note that we are here using the MNIST test data for *validation*, instead of for testing the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "validation_dataset = datasets.MNIST('./data', \n",
    "                                    train=False, \n",
    "                                    transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, \n",
    "                                                batch_size=batch_size, \n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test data are provided via data loaders that provide iterators over the datasets. The first element of training data (`X_train`) is a 4th-order tensor of size (`batch_size`, 1, 28, 28), i.e. it consists of a batch of images of size 1x28x28 pixels. `y_train` is a vector containing the correct classes (\"0\", \"1\", ..., \"9\") for each training digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the first 10 training digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x108 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize = 1.5\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i,:,:,:].numpy().reshape(28, 28), cmap=\"gray_r\")\n",
    "    plt.title('Class: {}'.format(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP network definition\n",
    "\n",
    "Let's define the network as a Python class.  We have to write the `__init__()` and `forward()` methods, and PyTorch will automatically generate a `backward()` method for computing the gradients for the backward pass.\n",
    "\n",
    "Finally, we define an optimizer to update the model parameters based on the computed gradients.  We select *stochastic gradient descent (with momentum)* as the optimization algorithm, and set *learning rate* to 0.01.  Note that there are [several different options](http://pytorch.org/docs/optim.html#algorithms) for the optimizer in PyTorch that we could use instead of *SGD*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=56, bias=True)\n",
      "  (fc1_drop): Dropout(p=0.2, inplace=False)\n",
      "  (bibd2): BibdLinear()\n",
      "  (fc3): Linear(in_features=49, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../bibd')\n",
    "from bibd_layer import BibdLinear\n",
    "\n",
    "r = 7\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, r*(r+1))\n",
    "        self.fc1_drop = nn.Dropout(0.2)\n",
    "        self.bibd2 = BibdLinear(r*(r+1), r*r, number_of_block=r)\n",
    "        self.fc3 = nn.Linear(r*r, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_drop(x)\n",
    "        x = F.relu(self.bibd2(x))\n",
    "        return F.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning\n",
    "\n",
    "Let's now define functions to `train()` and `validate()` the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, log_interval=200):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Loop over each batch from the training set\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Copy data to GPU if needed\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Zero gradient buffers\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        # Pass data through the network\n",
    "        output = model(data)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(loss_vector, accuracy_vector):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    for data, target in validation_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        val_loss += criterion(output, target).data.item()\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    val_loss /= len(validation_loader)\n",
    "    loss_vector.append(val_loss)\n",
    "\n",
    "    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train our model using the `train()` function.  An *epoch* means one pass through the whole training data. After each epoch, we evaluate the model using `validate()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.325233\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.180618\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.920563\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.196113\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.901234\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.604946\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.506741\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.593116\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.465387\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.419238\n",
      "\n",
      "Validation set: Average loss: 0.3852, Accuracy: 8932/10000 (89%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.304802\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.562604\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.445875\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.248973\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.443717\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.495356\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.423786\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.569024\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.171692\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.087772\n",
      "\n",
      "Validation set: Average loss: 0.2846, Accuracy: 9155/10000 (92%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.207855\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.558407\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.596013\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.620486\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.460162\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.170135\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.391833\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.349066\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.228995\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.730602\n",
      "\n",
      "Validation set: Average loss: 0.2386, Accuracy: 9286/10000 (93%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.365828\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.230962\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.388849\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.292248\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.159572\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.119742\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.182166\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.187297\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.593479\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.417677\n",
      "\n",
      "Validation set: Average loss: 0.2058, Accuracy: 9384/10000 (94%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.173158\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.326472\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.108175\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.148996\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.600152\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.101513\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.295306\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.239971\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.462009\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.076067\n",
      "\n",
      "Validation set: Average loss: 0.1844, Accuracy: 9429/10000 (94%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.177995\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.479120\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.300435\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.180941\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.221372\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.224049\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.132548\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.144853\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.293981\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.054545\n",
      "\n",
      "Validation set: Average loss: 0.1690, Accuracy: 9472/10000 (95%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.519582\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.349372\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.148233\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.364158\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.255596\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.095652\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.124344\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.384080\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.120463\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.097703\n",
      "\n",
      "Validation set: Average loss: 0.1532, Accuracy: 9530/10000 (95%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.223652\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.342912\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.274939\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.347590\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.035582\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.347511\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.074477\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.101816\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.148945\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.274845\n",
      "\n",
      "Validation set: Average loss: 0.1459, Accuracy: 9565/10000 (96%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.171165\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.233128\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.072580\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.246118\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.214615\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.215371\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.194000\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.642269\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.148188\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.105509\n",
      "\n",
      "Validation set: Average loss: 0.1387, Accuracy: 9579/10000 (96%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.153723\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.282184\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.112890\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.104593\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.287797\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.038197\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.254828\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.091341\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.136396\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.046422\n",
      "\n",
      "Validation set: Average loss: 0.1319, Accuracy: 9608/10000 (96%)\n",
      "\n",
      "CPU times: user 1min 33s, sys: 10.6 s, total: 1min 44s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
